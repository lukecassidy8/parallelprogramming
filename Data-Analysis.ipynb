{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02cd0534",
   "metadata": {},
   "source": [
    "# Vehicle Sales Data Analysis\n",
    "This notebook outlines the code and results of the ten data analysis tasks for the BS3220 Parallel Programming assignment. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ba7f75",
   "metadata": {},
   "source": [
    "### Import libraries and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e92837ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import sum, count, max, min, avg, col, rank, to_date, date_format, regexp_extract, row_number, first, last, format_number, substring\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"VehicleSalesCleaning\") \\\n",
    "    .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.csv(\"car_prices.csv\", header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72818841",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e0106bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "+----+-----+-------------------+----------+-----+------------+-----------------+-----+---------+--------+-----+--------+--------------------+-----+------------+--------------------+\n",
      "|year| make|              model|      trim| body|transmission|              vin|state|condition|odometer|color|interior|              seller|  mmr|sellingprice|            saledate|\n",
      "+----+-----+-------------------+----------+-----+------------+-----------------+-----+---------+--------+-----+--------+--------------------+-----+------------+--------------------+\n",
      "|2015|  Kia|            Sorento|        LX|  SUV|   automatic|5xyktca69fg566472|   ca|        5|   16639|white|   black|kia motors americ...|20500|       21500|Tue Dec 16 2014 1...|\n",
      "|2015|  Kia|            Sorento|        LX|  SUV|   automatic|5xyktca69fg561319|   ca|        5|    9393|white|   beige|kia motors americ...|20800|       21500|Tue Dec 16 2014 1...|\n",
      "|2014|  BMW|           3 Series|328i SULEV|Sedan|   automatic|wba3c1c51ek116351|   ca|       45|    1331| gray|   black|financial service...|31900|       30000|Thu Jan 15 2015 0...|\n",
      "|2015|Volvo|                S60|        T5|Sedan|   automatic|yv1612tb4f1310987|   ca|       41|   14282|white|   black|volvo na rep/worl...|27500|       27750|Thu Jan 29 2015 0...|\n",
      "|2014|  BMW|6 Series Gran Coupe|      650i|Sedan|   automatic|wba6b2c57ed129731|   ca|       43|    2641| gray|   black|financial service...|66000|       67000|Thu Dec 18 2014 1...|\n",
      "+----+-----+-------------------+----------+-----+------------+-----------------+-----+---------+--------+-----+--------+--------------------+-----+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Extracted Date Part:\n",
      "+--------------------+---------------+\n",
      "|            saledate|      date_part|\n",
      "+--------------------+---------------+\n",
      "|Tue Dec 16 2014 1...|Tue Dec 16 2014|\n",
      "|Tue Dec 16 2014 1...|Tue Dec 16 2014|\n",
      "|Thu Jan 15 2015 0...|Thu Jan 15 2015|\n",
      "|Thu Jan 29 2015 0...|Thu Jan 29 2015|\n",
      "|Thu Dec 18 2014 1...|Thu Dec 18 2014|\n",
      "+--------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Transformed Data:\n",
      "+--------------------+------------------+\n",
      "|            saledate|formatted_saledate|\n",
      "+--------------------+------------------+\n",
      "|Tue Dec 16 2014 1...|          12162014|\n",
      "|Tue Dec 16 2014 1...|          12162014|\n",
      "|Thu Jan 15 2015 0...|          01152015|\n",
      "|Thu Jan 29 2015 0...|          01292015|\n",
      "|Thu Dec 18 2014 1...|          12182014|\n",
      "+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the original data (optional, for verification)\n",
    "print(\"Original Data:\")\n",
    "df.show(5)\n",
    "\n",
    "df = df.filter(df.sellingprice != 1)\n",
    "\n",
    "# Extract the date part excluding time and timezone using regular expressions\n",
    "df = df.withColumn(\"date_part\", regexp_extract(col(\"saledate\"), r\"(\\w+\\s\\w+\\s\\d+\\s\\d+)\", 1))\n",
    "\n",
    "# Display the extracted date part (optional, for verification)\n",
    "print(\"Extracted Date Part:\")\n",
    "df.select(\"saledate\", \"date_part\").show(5)\n",
    "\n",
    "# Convert extracted string to date and format it to MMddyyyy\n",
    "df = df.withColumn(\"formatted_saledate\", date_format(to_date(col(\"date_part\"), \"EEE MMM dd yyyy\"), \"MMddyyyy\"))\n",
    "\n",
    "# Show the final transformed data to verify the transformation\n",
    "print(\"Transformed Data:\")\n",
    "df.select(\"saledate\", \"formatted_saledate\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec3f06c",
   "metadata": {},
   "source": [
    "### Task 1: Find the total sales for each item, both the number of units and the total price/cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1003f06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import sum, count\n",
    "\n",
    "# df.groupBy(\"make\", \"model\").agg(\n",
    "#     count(\"vin\").alias(\"units_sold\"), \n",
    "#     sum(\"sellingprice\").alias(\"total_revenue\") \n",
    "# ).show(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bdb4b8",
   "metadata": {},
   "source": [
    "### Task 2: Summarise the total sales of all items at each location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b2de7ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# salesPerState = df.groupBy(\"state\").agg(\n",
    "#     sum(\"sellingprice\").alias(\"total_revenue\")\n",
    "# ).orderBy(\"total_revenue\", ascending=False)\n",
    "\n",
    "# salesPerState.show(55)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cec6cd",
   "metadata": {},
   "source": [
    "### Task 3: List all products and their combined sales, grouped by their location of sale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "cb7e1d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------+-------------+\n",
      "|state|         make|         model|total_revenue|\n",
      "+-----+-------------+--------------+-------------+\n",
      "|   fl|       Nissan|        Altima|     40266403|\n",
      "|   ca|          BMW|      3 Series|     39475195|\n",
      "|   ca|     Infiniti|       G Sedan|     37101104|\n",
      "|   tx|         Ford|         F-150|     35473601|\n",
      "|   fl|       Toyota|         Camry|     33998428|\n",
      "|   ca|       Nissan|        Altima|     31781931|\n",
      "|   mi|         Ford|         F-150|     31000235|\n",
      "|   pa|       Nissan|        Altima|     27048715|\n",
      "|   ca|          BMW|      5 Series|     26879650|\n",
      "|   pa|         Ford|         F-150|     24072500|\n",
      "|   ca|Mercedes-Benz|       E-Class|     22858804|\n",
      "|   fl|        Lexus|        RX 350|     22784950|\n",
      "|   pa|        Honda|        Accord|     22761300|\n",
      "|   fl|     Infiniti|       G Sedan|     22361802|\n",
      "|   tn|         Ford|         F-150|     22239125|\n",
      "|   ca|Mercedes-Benz|       C-Class|     21891527|\n",
      "|   fl|       Toyota|       Corolla|     21380013|\n",
      "|   fl|         Ford|         F-150|     21126995|\n",
      "|   fl|          BMW|      3 Series|     20101150|\n",
      "|   fl|        Lexus|        ES 350|     20045850|\n",
      "|   il|       Nissan|        Altima|     19738811|\n",
      "|   nj|       Nissan|        Altima|     19725153|\n",
      "|   il|         Ford|        Escape|     18813627|\n",
      "|   ca|         NULL|          NULL|     18736376|\n",
      "|   tx|       Nissan|        Altima|     18414600|\n",
      "|   fl|        Lexus|        IS 250|     18136050|\n",
      "|   fl|         Ford|        Fusion|     17918806|\n",
      "|   fl|        Dodge| Grand Caravan|     17883136|\n",
      "|   fl|      Hyundai|        Sonata|     17566550|\n",
      "|   tx|    Chevrolet|Silverado 1500|     17510500|\n",
      "+-----+-------------+--------------+-------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TODO - Change\n",
    "\n",
    "combined_sales_by_state_and_product = df.groupBy(\"state\", \"make\", \"model\").agg(\n",
    "    sum(\"sellingprice\").alias(\"total_revenue\")\n",
    ").orderBy(\"total_revenue\", ascending=False)\n",
    "\n",
    "# Display the combined sales for each product by state\n",
    "combined_sales_by_state_and_product.show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72929101",
   "metadata": {},
   "source": [
    "### Task 4: Show the sales numbers for the item which sold the most units at each location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "216b679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_sales_by_state = df.groupBy(\"state\", \"make\", \"model\", \"trim\").agg(\n",
    "#     count(\"vin\").alias(\"units_sold\"),\n",
    "#     sum(\"sellingprice\").alias(\"total_revenue\")\n",
    "# )\n",
    "\n",
    "# # Define a window partitioned by state and ordered by units_sold in descending order\n",
    "# windowSpec = Window.partitionBy(\"state\").orderBy(col(\"units_sold\").desc())\n",
    "\n",
    "# # Rank items within each state and select the top item\n",
    "# top_item_by_state = item_sales_by_state.withColumn(\"rank\", rank().over(windowSpec)).filter(col(\"rank\") == 1)\n",
    "# top_item_by_state.show(400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bf3904",
   "metadata": {},
   "source": [
    "### Task 5: List all items that were sold within two months of your choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "bf6eb3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------------+------------------+\n",
      "|     make|   model|            saledate|formatted_saledate|\n",
      "+---------+--------+--------------------+------------------+\n",
      "|      BMW|3 Series|Thu Jan 15 2015 0...|          01152015|\n",
      "|    Volvo|     S60|Thu Jan 29 2015 0...|          01292015|\n",
      "|Chevrolet|  Camaro|Tue Jan 20 2015 0...|          01202015|\n",
      "|     Ford|  Fusion|Tue Jan 13 2015 1...|          01132015|\n",
      "|      BMW|5 Series|Tue Feb 03 2015 0...|          02032015|\n",
      "|      BMW|6 Series|Tue Jan 06 2015 1...|          01062015|\n",
      "|    Volvo|    XC70|Thu Feb 26 2015 0...|          02262015|\n",
      "|    Volvo|    XC70|Thu Feb 12 2015 0...|          02122015|\n",
      "|     Audi|     SQ5|Thu Jan 29 2015 0...|          01292015|\n",
      "|    Buick|  Verano|Tue Jan 06 2015 0...|          01062015|\n",
      "|      BMW|3 Series|Thu Jan 15 2015 0...|          01152015|\n",
      "|      BMW|      M5|Tue Jan 13 2015 0...|          01132015|\n",
      "|      BMW|3 Series|Thu Jan 15 2015 0...|          01152015|\n",
      "| Cadillac|     ELR|Wed Feb 04 2015 0...|          02042015|\n",
      "|      BMW|6 Series|Tue Jan 06 2015 0...|          01062015|\n",
      "|Chevrolet|   Cruze|Thu Jan 22 2015 0...|          01222015|\n",
      "|      Kia|    K900|Tue Feb 17 2015 0...|          02172015|\n",
      "|Chevrolet|  Malibu|Wed Jan 14 2015 0...|          01142015|\n",
      "|      Kia|    K900|Tue Jan 20 2015 0...|          01202015|\n",
      "|      BMW|6 Series|Tue Jan 06 2015 1...|          01062015|\n",
      "+---------+--------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TODO - change\n",
    "\n",
    "df_filtered = df.filter((col(\"formatted_saledate\").substr(1,2) == \"01\") | (col(\"formatted_saledate\").substr(1,2)==\"02\"))\n",
    "\n",
    "df_filtered.select(\"make\", \"model\", \"saledate\", \"formatted_saledate\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beae7bee",
   "metadata": {},
   "source": [
    "### Task 6: Identify the item which has the lowest overall sales, both for the dataset as a whole and for each sales location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "57686fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# salesPerCar = df.groupBy(\"make\", \"model\").agg(\n",
    "#     count(\"*\").alias(\"unitsSold\")\n",
    "# )\n",
    "# salesPerCarPerState = df.groupBy(\"state\", \"make\", \"model\").agg(\n",
    "#     count(\"*\").alias(\"unitsSold\")\n",
    "# )\n",
    "# lowestCarSale = salesPerCar.orderBy(\"unitsSold\").first()\n",
    "\n",
    "# windowSpec = Window.partitionBy(\"state\").orderBy(\"unitsSold\")\n",
    "# lowestCarSaleByState = salesPerCarPerState.withColumn(\"row_number\", row_number().over(windowSpec)).filter(col(\"row_number\") == 1)\n",
    "\n",
    "# print(\"Lowest selling car:\")\n",
    "# print(lowestCarSale)\n",
    "# print(\"Lowest Selling Car by State:\")\n",
    "# lowestCarSaleByState.show(55)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359e448a",
   "metadata": {},
   "source": [
    "### Task 7: Find the most expensive and least expensive item for each location where sales occurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2d595f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# windowExpensive = Window.partitionBy(\"state\").orderBy(col(\"sellingprice\").desc())\n",
    "# windowCheap = Window.partitionBy(\"state\").orderBy(col(\"sellingprice\").asc())\n",
    "\n",
    "# dfRanked = df.withColumn(\"rank_desc\", row_number().over(windowExpensive)) \\\n",
    "#              .withColumn(\"rank_asc\", row_number().over(windowCheap))\n",
    "\n",
    "# mostExpensive = dfRanked.filter(col(\"rank_desc\") == 1).select(\n",
    "#     \"state\", \"make\", \"model\", \"sellingprice\"\n",
    "# )\n",
    "# leastExpensive = dfRanked.filter(col(\"rank_asc\") == 1).select(\n",
    "#     \"state\", \"make\", \"model\", \"sellingprice\"\n",
    "# )\n",
    "\n",
    "# print(\"Most Expensive Car Sale by State:\")\n",
    "# mostExpensive.show(10)\n",
    "# print(\"Least Expensive Car Sale by State:\")\n",
    "# leastExpensive.show(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4441a74",
   "metadata": {},
   "source": [
    "### Task 8: Calculate the average cost of an item at each location within your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "089015a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# averagePriceByState = df.groupBy(\"state\").agg(\n",
    "#     format_number(avg(\"sellingprice\"), 2).alias(\"average_selling_price\")\n",
    "# )\n",
    "# averagePriceByState = averagePriceByState.orderBy(\"state\")\n",
    "\n",
    "# print(\"Average Selling Price by State:\")\n",
    "# averagePriceByState.show(55)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc3e524",
   "metadata": {},
   "source": [
    "### Task 9: Based on your individual dataset, create a set of variables which can be used as broadcast variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda0b7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "949d7bcb",
   "metadata": {},
   "source": [
    "### Task 10: Complete one other query to analyse the data, based on your individual dataset. This query should be relevant to your own specific dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4a6ff1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performing state for sales:\n",
      "+-----+-------------+\n",
      "|state|numberOfSales|\n",
      "+-----+-------------+\n",
      "|   fl|        82945|\n",
      "|   ca|        73147|\n",
      "|   pa|        53907|\n",
      "|   tx|        45912|\n",
      "|   ga|        34749|\n",
      "|   nj|        27784|\n",
      "|   il|        23478|\n",
      "|   nc|        21845|\n",
      "|   oh|        21575|\n",
      "|   tn|        20895|\n",
      "+-----+-------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Best performing state for revenue:\n",
      "+-----+------------+\n",
      "|state|totalRevenue|\n",
      "+-----+------------+\n",
      "|   fl|  1151064556|\n",
      "|   ca|  1061077776|\n",
      "|   pa|   861234573|\n",
      "|   tx|   606495360|\n",
      "|   ga|   448927413|\n",
      "|   nj|   378115350|\n",
      "|   tn|   355418608|\n",
      "|   il|   347290026|\n",
      "|   oh|   310822810|\n",
      "|   mo|   231647138|\n",
      "+-----+------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Best average revenue per sale:\n",
      "+-----+-----------------------+\n",
      "|state|formattedAverageRevenue|\n",
      "+-----+-----------------------+\n",
      "|   on|              17,812.62|\n",
      "|   tn|              17,009.74|\n",
      "|   pa|              15,976.30|\n",
      "|   co|              15,877.80|\n",
      "|   nv|              15,097.77|\n",
      "|   mi|              14,886.22|\n",
      "|   il|              14,792.15|\n",
      "|   ca|              14,506.10|\n",
      "|   mo|              14,466.19|\n",
      "|   oh|              14,406.62|\n",
      "+-----+-----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query: to show the best performing months across all states and all dealerships\n",
    "\n",
    "\n",
    "stateSalesAndRevenue = df.groupBy(\"state\").agg(count(\"*\").alias(\"numberOfSales\"), sum(\"sellingprice\").alias(\"totalRevenue\"))\n",
    "\n",
    "stateSales = df.groupBy(\"state\").agg(count(\"*\").alias(\"numberOfSales\"))\n",
    "stateRevenue = df.groupBy(\"state\").agg(sum(\"sellingprice\").alias(\"totalRevenue\"))\n",
    "stateAverage = df.groupBy(\"state\").agg(avg(\"sellingprice\").alias(\"averageRevenuePerSale\"))\n",
    "\n",
    "bestStateForSales = stateSales.orderBy(col(\"numberOfSales\").desc())\n",
    "bestStateForRevenue = stateRevenue.orderBy(col(\"totalRevenue\").desc())\n",
    "bestStateForAverageRevenuePerSale = stateAverage.orderBy(col(\"averageRevenuePerSale\").desc())\n",
    "\n",
    "#Formatting 2DP for revenue after ordering as was causing table to sort lowest first, not highest first \n",
    "formattedBestStateForAverageRevenue = bestStateForAverageRevenuePerSale.withColumn(\n",
    "    \"formattedAverageRevenue\", format_number(col(\"averageRevenuePerSale\"), 2)\n",
    ")\n",
    "\n",
    "print(\"Best performing state for sales:\")\n",
    "bestStateForSales.show(10)\n",
    "print(\"Best performing state for revenue:\")\n",
    "bestStateForRevenue.show(10)\n",
    "print(\"Best average revenue per sale:\")\n",
    "formattedBestStateForAverageRevenue.select(\"state\", \"formattedAverageRevenue\").show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
